Вариант 5. Покрытие множеств с жадным алгоритмом
Задача: реализовать жадный ln(n)-аппроксимационный алгоритм для задачи о покрытии
множеств.
Требования:
- Входные данные: универсальное множество и семейство подмножеств
- Выход: минимальное количество выбранных множеств
- Вывести выбранные множества и общее количество элементов
Входные данные:
Универсум: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
Подмножества: S1={1,2,3}, S2={2,4,6}, S3={3,5,7},
 S4={1,4,7,10}, S5={5,6,8,9}

Описание алгоритма:

Задать входные данные:
Определить универсум U и семейство подмножеств S = {S1, S2, ..., Sm}.
Инициализация:
Создать множество непокрытых элементов uncovered = U.
Создать пустой список выбранных множеств chosen_sets = [].
Основной цикл:
Пока uncovered не пусто, выполнять:
Для каждого множества Si вычислить new_elements = Si ∩ uncovered.
Определить множество best_set, для которого len(new_elements) максимально.
Добавить best_set в chosen_sets.
Обновить uncovered = uncovered - best_set.
Завершение:
После выхода из цикла вернуть chosen_sets как результат — набор выбранных множеств, покрывающих универсум.

Синтаксис:

set(...) — создание множества. Поддерживает & (пересечение), | (объединение), - (разность).
for name, s in subsets.items() — итерация по парам ключ-значение словаря.
while uncovered: — цикл, выполняется пока условие истинно (пустое множество считается False).
set.update(other_set) — добавляет элементы другого множества.
uncovered -= best_set_elements — вычитание множества (удаление всех элементов best_set_elements из uncovered).

Временная сложность: O(m · n²) в худшем случае, где m — количество подмножеств, n — размер универсума.
Анализ: Алгоритм на каждой итерации перебирает все m множеств и вычисляет пересечения с непокрытыми элементами (O(m·n)), при до n итерациях цикла, что даёт итоговую сложность O(m·n²).

Ответы на контрольные вопросы:

1. Определение приближенных алгоритмов — Приближенный алгоритм (approximation algorithm) — это алгоритм для NP-трудной задачи, который за полиномиальное время строит решение гарантированного качества: значение полученного решения находится в некотором множителе α от оптимального. Цель — получить «достаточно хорошее» решение быстро, когда точный алгоритм за полиномиальное время неизвестен.

2. Коэффициент аппроксимации (α) — Для задачи минимизации α-аппроксимация означает: для любого входа алгоритм возвращает решение с ценой (A), такое что (A \le \alpha \cdot OPT), где (OPT) — стоимость оптимального решения. α характеризует максимально возможное ухудшение по сравнению с оптимумом.

3. PTAS vs FPTAS — PTAS (Polynomial-Time Approximation Scheme) — семейство алгоритмов parameterized по ε>0: для каждого фиксированного ε даёт ((1+ε))-приближение за полиномиальное (в размере входа) время, но время может зависеть произвольно от (ε) (например (n^{O(1/ε)})).
   FPTAS (Fully PTAS) — более жёсткий: время полиномиально и по размеру входа, и по (1/ε) (например (O(n^2/ε))). Итого: FPTAS = PTAS с дополн. требованием полиномиальности по (1/ε).

4. Жадный алгоритм для вершинного покрытия — почему 2-аппроксимация (доказательство).
   Алгоритм: пока есть ребро, возьми любое ребро ((u,v)), добавь оба конца (u) и (v) в покрытие, удаляй все инцидентные ребра.
   Доказательство: пусть (M) — набор ребер, выбранных алгоритмом (они попарно не пересекаются, т.к. после выбора ребра удаляются все инцидентные ему ребра → (M) — совпадающее с «максимальным» по построению паросочетанием). Любое покрытие вершин должно покрыть каждое ребро из (M) хотя бы одной вершиной, значит (|OPT| \ge |M|). Алгоритм выбирает по 2 вершины на каждое ребро из (M), значит (|ALG| = 2|M| \le 2|OPT|). Следовательно — 2-аппроксимация.

5. Жадный алгоритм для 0-1 рюкзака — почему не гарантирует оптимум (контрпример).
   Жадный по удельной ценности (v/w) может ошибаться. Контрпример: вместимость (W=50). Предметы: A — (w=30, v=60) (ρ=2), B — (w=30, v=60) (ρ=2), C — (w=50, v=99) (ρ=1.98). Жадный по ρ возьмёт A (или B) и уже не сможет взять второй — итог value = 60. Оптимум — взять C, value = 99. Ошибка очевидна.

6. Различие дробного и 0-1 рюкзака — В дробном рюкзаке (fractional knapsack) допускается брать дробные доли предметов; жадный по (v/w) даёт оптимум. В 0-1 рюкзаке предмет либо берётся полностью, либо нет — дробные части запрещены; из-за этого жадный по удельной ценности не всегда оптимален.

7. Коэффициент аппроксимации для составления расписания (list scheduling) — корректное значение и доказательство.
   Правильная гарантия для простого жадного алгоритма (list scheduling) на (m) одинаковых машин — фактор (;2-\tfrac{1}{m};) (не (2(1-1/m))).
   Краткое доказательство: пусть (C_{max}) — время завершения жадного решения, (t) — работа последней завершившейся задачи, (P=\sum p_j). Когда задача (t) назначалась, все машины имели загрузку ≥ (C_{max}-p_t) (иначе она не была бы назначена на наименее загруженную). Значит (m(C_{max}-p_t) \le P-p_t). Отсюда (C_{max} \le \tfrac{P}{m} + p_t(1-\tfrac{1}{m})). Так как оптимум (OPT \ge \tfrac{P}{m}) и (OPT \ge p_t), получаем (C_{max} \le OPT + (1-\tfrac{1}{m})OPT = (2-\tfrac{1}{m})OPT).

8. Алгоритм Кристофидеса (TSP) — этапы и почему 1.5-аппроксимация.
   Этапы: (1) найди MST (минимальное остовное дерево), (2) найди минимум-вес совершенное паросочетание на вершинах нечётной степени MST, (3) сложи веса MST и паросочетания → образуется эйлеров граф, (4) пройдём по эйлеровому обходу и сделаем «shortcutting» (пропуск уже посещённых вершин) — получится гамильтонов цикл.
   Почему 1.5: вес MST ≤ OPT (удаление ребра из оптимального тура даёт остов). Вес минимального совершенного паросочетания на нечётных вершинах ≤ 0.5·OPT (в метриках с неравенством треугольника можно разбить маршруты оптимума и получить такое утверждение). Итого итоговый цикл ≤ MST + matching ≤ OPT + 0.5·OPT = 1.5·OPT.

9. Жадный алгоритм для покрытия множеств — коэффициент аппроксимации и почему.
   Коэффициент: (H_n = 1 + \tfrac12 + \tfrac13 + \dots + \tfrac{1}{n} \le 1+\ln n) (гармоническое число), часто говорят «(O(\ln n))-аппроксимация» или конкретно (H_n)-аппроксимация.
   Почему (интуитивно): на каждой итерации жадный выбирает множество, покрывающее максимально возможную долю оставшихся элементов; анализ через «переходную оценку» показывает, что количество выбранных множеств не превосходит (H_n) раз оптимального (формальное доказательство использует «чёрные ящики» и суммирование вкладов по оставшимся элементам).

10. Эвристические алгоритмы vs приближенные — Приближенные алгоритмы имеют теоретически доказанный множитель качества (аппроксимации) и полиномиальное время. Эвристики — практические правила/методы без жёстких гарантий; они часто дают хорошие решения на практике, но без строгого worst-case фактора. Примеры эвристик: жадные эвристики, локальный поиск, генетические алгоритмы, эвристики первой пригодности в маршрутизации. Примеры приближенных: алгоритм Кристофидеса для метрического TSP (1.5-аппрокс.), жадный для Set Cover (H_n).

11. Имитация отжига — принцип и роль температуры.
    Принцип: случайный локальный поиск, который иногда принимает хуже решение, чтобы уйти от локальных оптимумов. Параметр «температура» (T) управляет вероятностью принятия ухудшающих переходов: при большой (T) алгоритм легко прыгает; при медленном охлаждении (T\to0) переходы становятся всё более строгими. Хорошая схема охлаждения — ключ к качеству.

12. Критерий Метрополиса — формула и смысл.
    Для изменения с приростом стоимости (\Delta = f(new)-f(current)):

* если (\Delta \le 0) — принимаем обязательно;
* иначе принимаем с вероятностью ( \exp(-\Delta / T) ).
  Это даёт ненулевую вероятность принять худшее решение (тем самым избегая застревания), которая убывает с уменьшением (T) и с ростом (\Delta).

13. Табу-поиск — концепция табу-листа и роль.
    Табу-лист хранит недавние ходы/решения и запрещает их повторение в течение некоторого времени (tabu tenure). Это предотвращает циклы и зацикливание в небольшом подмножестве пространства решений, позволяя методу исследовать новые области.

14. Критерий аспирации.
    Аспирация — правило, позволяющее игнорировать запрет из табу-листа, если move даёт очень хорошее решение (например, улучшает лучший найденный глобально). Применяется, чтобы не блокировать потенциально существенное улучшение ради чистоты запретов.

15. Локальный оптимум и почему нужны метаэвристики.
    Локальный оптимум — решение, у которого все близкие (в операторе соседства) варианты хуже, хотя где-то в пространстве решений есть лучшее глобальное. Метаэвристики нужны потому, что простые локальные стратегии (горячая жадность) часто застревают в локальном оптимуме; метаэвристики (SA, Tabu, GA и др.) дают механизмы перехождения через «барьеры» и исследования пространства решений.

16. Оператор соседства — правило, которое для данного решения генерирует «соседние» решения. Примеры: в TSP — перестановка двух вершин (2-opt), в рюкзаке — замена одного предмета на другой, в раскраске графа — смена цвета одной вершины.

17. Генетические алгоритмы — основные операции.

* *Отбор* (selection): выбираются родительские хромосомы по фитнес-функции (турнир, рулетка и т.д.).
* *Кроссовер* (crossover): комбинирование генов двух родителей для получения потомков (one-point, two-point, PMX для перестановок).
* *Мутация* (mutation): случайное внесение небольших изменений в потомка для сохранения разнообразия (пример: флип бита, swap двух позиций).

18. NP-сложность — зачем приближённые алгоритмы.
    NP-полные задачи не имеют известных полиномиальных алгоритмов для точного решения (и, скорее всего, не имеют). Для больших входов точный перебор невозможен по времени → приближённые/эвристические дают приемлемые по качеству решения за полиномиальное время.

19. Точность vs скорость — компромисс.
    Улучшение точности зачастую требует большего времени (глубже искать, больше итераций, более точные схемы). Приближённые алгоритмы балансируют: разрешённая потеря качества (коэффициент аппрокс.) позволяет значительно сократить время; эвристики часто выбирают практическую скорость в обмен на отсутствие строгой гарантии.

20. 5 реальных приложений приближённых/эвристических алгоритмов:

* логистика и маршрутизация (Vehicle Routing Problem — планирование доставки),
* планирование и диспетчеризация задач на производстве (scheduling),
* упаковка и размещение грузов (bin packing, cutting stock),
* распределение ресурсов и портфельная оптимизация в финансах,
* оптимизация топологии и маршрутов в сетях (например, дизайн телеком-сети).
