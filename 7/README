Вариант 5. Покрытие множеств с жадным алгоритмом
Задача: реализовать жадный ln(n)-аппроксимационный алгоритм для задачи о покрытии
множеств.
Требования:
- Входные данные: универсальное множество и семейство подмножеств
- Выход: минимальное количество выбранных множеств
- Вывести выбранные множества и общее количество элементов
Входные данные:
Универсум: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}
Подмножества: S1={1,2,3}, S2={2,4,6}, S3={3,5,7},
 S4={1,4,7,10}, S5={5,6,8,9}

Описание алгоритма:

Задать входные данные:
Определить универсум U и семейство подмножеств S = {S1, S2, ..., Sm}.
Инициализация:
Создать множество непокрытых элементов uncovered = U.
Создать пустой список выбранных множеств chosen_sets = [].
Основной цикл:
Пока uncovered не пусто, выполнять:
Для каждого множества Si вычислить new_elements = Si ∩ uncovered.
Определить множество best_set, для которого len(new_elements) максимально.
Добавить best_set в chosen_sets.
Обновить uncovered = uncovered - best_set.
Завершение:
После выхода из цикла вернуть chosen_sets как результат — набор выбранных множеств, покрывающих универсум.

Синтаксис:

set(...) — создание множества. Поддерживает & (пересечение), | (объединение), - (разность).
for name, s in subsets.items() — итерация по парам ключ-значение словаря.
while uncovered: — цикл, выполняется пока условие истинно (пустое множество считается False).
set.update(other_set) — добавляет элементы другого множества.
uncovered -= best_set_elements — вычитание множества (удаление всех элементов best_set_elements из uncovered).

Временная сложность: O(m · n²) в худшем случае, где m — количество подмножеств, n — размер универсума.
Анализ: Алгоритм на каждой итерации перебирает все m множеств и вычисляет пересечения с непокрытыми элементами (O(m·n)), при до n итерациях цикла, что даёт итоговую сложность O(m·n²).

Ответы на контрольные вопросы:

1. Определение приближённых алгоритмов
Приближённый алгоритм — это алгоритм, который находит решение близкое к оптимальному за полиномиальное время. Его цель — получить приемлемое решение для NP-сложных задач, где точное решение слишком дорого по времени.

2. Коэффициент аппроксимации
Коэффициент аппроксимации α для задачи минимизации — это отношение найденного решения к оптимальному, не превышающее α. Он показывает, насколько решение может отличаться от оптимального.

3. PTAS и FPTAS
PTAS — схема, работающая за полиномиальное время при фиксированном ε, а FPTAS — полиномиальна и по размеру входа, и по 1/ε. FPTAS быстрее при изменении точности.

4. Жадный алгоритм для вершинного покрытия
Жадный алгоритм выбирает рёбра и обе их вершины, обеспечивая, что каждая вершина покрывает не более одного ребра оптимального решения. Поэтому решение не хуже чем в 2 раза от оптимального (2-аппроксимация).

5. Жадный алгоритм для рюкзака
Жадный алгоритм 0–1 рюкзака выбирает предметы по удельной ценности, но может пропустить выгодную комбинацию меньших предметов. Контрпример: предметы (вес,ценность) (2,10), (3,14), (4,15) при весе рюкзака 4 — жадный возьмёт (2,10), а оптимум — (3,14).

6. Различие дробного и 0–1 рюкзака
В дробном рюкзаке можно брать часть предмета, в 0–1 — только целиком. Поэтому дробный решается оптимально жадным алгоритмом, а 0–1 — нет.

7. Коэффициент аппроксимации для составления расписания
Жадный алгоритм распределения задач по m машинам имеет коэффициент аппроксимации 2(1−1/m), так как ни одна машина не будет нагружена более чем вдвое относительно оптимального распределения.

8. Алгоритм Кристофидеса
Этапы: построение минимального остовного дерева, добавление кратных рёбер для вершин нечётной степени, построение эйлерова и гамильтонова пути. Даёт 1.5-аппроксимацию для метрического TSP.

9. Жадный алгоритм для покрытия множеств
Жадный алгоритм имеет коэффициент аппроксимации ln(n), так как на каждом шаге выбирает множество, покрывающее максимум непокрытых элементов, уменьшая задачу логарифмически.

10. Эвристические алгоритмы
Эвристические алгоритмы не гарантируют аппроксимации, а лишь стремятся к «хорошему» решению на практике. Примеры: имитация отжига, табу-поиск, генетические алгоритмы.

11. Имитация отжига
Алгоритм случайно изменяет решение, иногда принимая худшие, чтобы избежать локального оптимума. Параметр «температура» управляет вероятностью таких переходов.

12. Критерий Метрополиса
Формула: P = exp(−ΔE/T), где ΔE — ухудшение решения, T — температура. Она определяет вероятность принятия худшего решения.

13. Табу-поиск
Табу-лист хранит недавние перемещения или решения, чтобы избежать возврата к ним и повторного цикла.

14. Критерий аспирации
Критерий аспирации разрешает игнорировать запрет табу-листа, если найдено лучшее решение, чем текущее лучшее.

15. Локальный поиск
Локальный оптимум — решение, которое нельзя улучшить небольшими изменениями. Метаэвристики нужны, чтобы выходить за его пределы.

16. Оператор соседства
Оператор соседства определяет способ перехода от текущего решения к «соседнему». Примеры: обмен элементов, перестановка, добавление или удаление.

17. Генетические алгоритмы
Основные операции: отбор лучших решений, кроссовер — обмен частями между ними, мутация — случайное изменение для разнообразия.

18. NP-сложность
Приближённые алгоритмы применяются, потому что NP-сложные задачи не решаются точно за полиномиальное время, и точные методы слишком медленны.

19. Точность и скорость
Чем выше точность приближения, тем больше время работы. Компромисс заключается в балансе между скоростью и качеством решения.

20. Применение в практике
Примеры: планирование производства, маршрутизация транспорта, составление расписаний, упаковка грузов, проектирование сетей связи.
